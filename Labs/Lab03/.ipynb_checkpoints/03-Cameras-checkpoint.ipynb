{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer Vision, Lab 03: Cameras (and lenses)\n",
    "\n",
    "Today we'll learn about cameras, lenses, and how to calibrate a camera.\n",
    "Some references for this material:\n",
    "\n",
    " - https://docs.opencv.org/master/d4/d94/tutorial_camera_calibration.html\n",
    " - Halcon Manual\n",
    " - https://www.baslerweb.com/\n",
    " - https://www.baslerweb.com/en/products/tools/lens-selector/\n",
    " - https://docs.opencv.org/master/dc/dbb/tutorial_py_calibration.html\n",
    " - https://learnopencv.com/camera-calibration-using-opencv/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Systems\n",
    "\n",
    "The camera system is an important module in any machine vision system. The camera sytem integrates with an overall machine vision system as follows.\n",
    "\n",
    "<img src=\"img/lab04-1.png\" width=\"600\"/>\n",
    "\n",
    "The important parameters in a camera system are:\n",
    "\n",
    " 1. Resolution: size of relevant aspect of object of interest.\n",
    " 2. Field of View (FOV): The area the camera captures. HFOV and VFOV indicate the horizontal and vertical FOVs.\n",
    " 3. Working Distance (WD): Distance between the camera and object. Fixed in an industrial system or variable in other applications.\n",
    " 4. Sensor Size: Size of the CCD or CMOS image sensor chip on the digital camera's circuit board.\n",
    " 5. Depth of Field (DOF): Distance between the nearest and farthest objects that are in focus.\n",
    " 6. Image Resolution: Size of image, $(w \\times h)$. Standard sizes such as 1920$\\times$1080 HD are referred to by the vertical resolution,\n",
    "    e.g. 1080p.\n",
    " 7. Pixel: Grayscale, RGB, multispectral, etc. For a fixed working distance, a pixel's backprojection has a fixed size, e.g., 2 mm per pixel.\n",
    " 8. Object Resolution: size of object of interest when imaged at the minimum size (e.g., faces at 20$\\times$20 or\n",
    "    humans at 64$\\times$128).\n",
    " 9. Focal Length: Distance between the image plane and the optical center of the camera, measured in pixels or mm.\n",
    " 10. Magnification: Ratio between sensor size and FOV.\n",
    "\n",
    "<img src=\"img/lab04-2.png\" width=\"800\"/>\n",
    "\n",
    "DOF varies depending on aperture:\n",
    "\n",
    "<img src=\"img/lab04-3.png\" width=\"400\"/>\n",
    " \n",
    "### Image Sensors\n",
    " \n",
    "When an image is captured by the image sensor, the state of each photoreceptor\n",
    "is saved then transferred to host memory. Image sensors in digital cameras and\n",
    "industrial sensors may be one of two types:\n",
    "\n",
    " - CCDs convert photoreceptor charges to analog voltages then digitized off-chip\n",
    " - CMOS sensors have separate digitization circuitry for every pixel\n",
    "\n",
    "Early fabrication techniques in the 1970s and 1980s were more suitable for CCDs, so available CCD sensors delivered much higher quality images and therefore\n",
    "dominated machine vision. In the 1990s, mobile phone commoditization started pushing CMOS technology, and now the available CMOS sensors are equal to or greater\n",
    "than CCDs in quality and much cheaper, though CCDs still deliver higher quality NIR imaging than CMOS sensors.\n",
    "\n",
    "Image sensor size is the main way to adjust the quality of the image output. Early on, most sensors had 4:3 aspect ratios, but now HD resolutions with 16:9\n",
    "ratios are becoming more common.\n",
    " \n",
    "<img src=\"img/lab04-4.png\" width=\"500\"/>\n",
    "\n",
    "Depending on the size and density of the photoreceptors on the image sensor, we get different image resolutions.\n",
    "\n",
    "<img src=\"img/lab04-5.jpg\" width=\"400\"/>\n",
    "\n",
    "### How to know if resolution is suitable for your work?\n",
    "\n",
    "The International Standards Organization has standard 12233, which\n",
    "defines various standardized charts that can be used to assess the\n",
    "quality of an image. Here is the \"legacy\" (pre-2000) chart:\n",
    "\n",
    "<img src=\"img/lab04-6.jpg\" width=\"800\"/>\n",
    "\n",
    "You can purchase charts from the ISO or print one yourself. See\n",
    "[Stephen Westin's Cornell Graphics web page on the ISO resolution chart](https://www.graphics.cornell.edu/~westin/misc/res-chart.html)\n",
    "for more detail.\n",
    "\n",
    "A rough idea can be obtained by considering the physical size of the smallest detail you want to analyze, considering how accurately\n",
    "you want to analyze it (the minimum number of pixels that should span the detail), then using that to calculate the necessary image\n",
    "resolution, lens focal length, and working distance. For example, suppose\n",
    "\n",
    "1. You want to detect cracks in a surface object that are a minimum 0.5. mm wide.\n",
    "2. You believe your crack detection algorithm requires at least 4 pixels of width\n",
    "   to ensure accurate detection (8 pixels per mm).\n",
    "3. You like the image quality and price of a 2 MP HD camera with a 50 degree HFOV.\n",
    "\n",
    "Since object size in pixels is $x=fX/Z$, we can write $$4 \\text{pixels} = f \\text{pixels} \\times 0.5 \\text{mm} / D.$$\n",
    "To get $f$, we know that $$\\tan(25^\\circ) = 960 / f,$$\n",
    "so $f = 2058.7$ and $D = 0.2573$ m. If a 26 cm working distance\n",
    "is OK for our application, the last step would be to ensure that the camera can focus on objects at that distance and make sure\n",
    "the DOF around a focus of 26 cm is sufficient.\n",
    "\n",
    "### Frame rate\n",
    "\n",
    "Another parameter that is important in most applications is the camera's frame rate. It is measured in frames per second.\n",
    "When you are imaging objects in motion, you should consider the maximum object velocity at the minimum working distance. That\n",
    "will tell you the maximum object displacement to expect per frame. For object tracking, you would want to ensure a fast enough\n",
    "frame rate that successive images of the moving object overlap sufficiently to have high confidence when associating the object\n",
    "appearance in a new frame with the object's appearance in the previous frame.\n",
    "\n",
    "Three other factors are related to frame rate: exposure time, shutter type, and interlacing.\n",
    "\n",
    "A short exposure time will minimize motion blur but will also decrease contrast. A longer exposure time will allow more light\n",
    "to reach the sensor, improving contrast but also increasing motion blur.\n",
    "\n",
    "The shutter can be global (CCD sensors and some CMOS sensors) or rolling (most CMOS sensors). A global shutter captures the entire\n",
    "image simultaneously, while a rolling shutter exposes sensor elements sequentially. If the shutter is fast enough relative to object motion,\n",
    "the shutter type is unimprotant. But if object motion (or camera motion) is high, a global shutter is preferred.\n",
    "\n",
    "Interlacing means that multiple passes are required to piece together the image. For example, even-numbered rows may be imaged on the\n",
    "first pass and odd-numbered rows may be imaged on the second pass. Interlacing is not common on modern sensors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Lens Specifications\n",
    "\n",
    "Lens specifications have two important measurements: Focal Length and Aperture (F-Stop)\n",
    "\n",
    "### Aperture (F-Stop)\n",
    "\n",
    "Aperture (called \"F-Stop\" in commercial camera specifications)\n",
    "indicates the width of the opening allowing light into the lens.\n",
    "Aperture (A) is measured relative to focal length:\n",
    "\n",
    "$$A = \\frac{f}{S},$$\n",
    "\n",
    "where $S$ is the \"aperture scale.\" Smaller aperture scales mean more light than\n",
    "larger aperture scales.\n",
    "\n",
    "<img src=\"img/lab04-7.jpg\" width=\"600\"/>\n",
    "\n",
    "When illumination is low, you may need larger apertures (smaller aperture scale numbers):\n",
    "\n",
    "<img src=\"img/lab04-9.jpg\" width=\"600\"/>\n",
    "\n",
    "And conversely, when light is especially bright,\n",
    "you may need smaller apertures. Aperture has interesting effects\n",
    "on especially bright light sources like the sun:\n",
    "\n",
    "<img src=\"img/lab04-8.jpg\" width=\"500\"/>\n",
    "\n",
    "But more importantly, when you have good illumination, you can afford to reduce the aperture\n",
    "(increase the aperture number), which has the benefit of giving you a larger DOF:\n",
    "\n",
    "<img src=\"img/lab04-10.jpg\" width=\"500\"/>\n",
    "\n",
    "Obviously, you would like to have a large DOF for a mobile robot, so you might want a very small\n",
    "aperture, but on the other hand, you also want a wide field of view (shorter focal length),\n",
    "which reduces your relative aperture size.\n",
    "\n",
    "### Focal length\n",
    "\n",
    "Focal length is the distance between the image sensor and the center of projection. In camera\n",
    "specifications, it is measured in mm, whereas in machine vision calculations, it is measured in pixels.\n",
    "Longer focal lengths give more zoom and smaller FOV.\n",
    "\n",
    "<img src=\"img/lab04-11.png\" width=\"1000\"/>\n",
    "\n",
    "A small focal length is great for imaging a wide field of view, but spreading the image out so much\n",
    "also typically requires a more convex lens, which increases the radial distortion.\n",
    "\n",
    "<img src=\"img/lab04-12.png\" width=\"800\"/>\n",
    "\n",
    "<img src=\"img/lab04-13.gif\" width=\"400\"/>\n",
    "\n",
    "### Planar Perspective Correction\n",
    "\n",
    "When your camera's principal axis is not orthogonal to the surface you're imaging, you will experience perspective distortion. As\n",
    "we've seen in class, if the object is truly planar, we can correct the image using a 4-point homography.\n",
    "\n",
    "### Radial Distortion\n",
    "\n",
    "The word \"distortion\" might be used to describe any kind of warping of an object due to depth, non-orthogonal principal axis, or\n",
    "\"bending\" of straight lines. In computer vision, we normally reserve the word \"distortion\" to refer to non-pinhole effects arising\n",
    "from the use of a lens to achieve the desired projection onto the image sensor. Non-pinhole distortion is either *radial* (warping\n",
    "along a vector emanting from a center of distortion), which is very common, especially with wide angle lenses, and *tangential*\n",
    "(warping orthogonal to the radial direction), which is less common and normally arises due to imprecise lens mounting. Getting precise\n",
    "measurements from a camera system requires either taking distortion into account or eliminating it. Distortion\n",
    "can be eliminated using optical techniques (using compound lenses and other hardware techniques), but this is expensive and possibly bulky.\n",
    "A more practical solution to eliminate distortion is to model the distortion function of your camera system then either use that model\n",
    "in your calculations or rectify every image before further processing.\n",
    "\n",
    "The modeling process is called *spatial calibration* and uses a known calibration pattern:\n",
    "\n",
    "<img src=\"img/lab04-14.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geometric Camera Parameters\n",
    "\n",
    "Knowing the camera fundamentals above, we can use a calibration\n",
    "process to calculate camera parameters in geometric form. We'll assume\n",
    "the camera's optical center as the origin of a 3D coordinate reference frame\n",
    "and the principal point of the camera as the point in the image at which the\n",
    "camera's principal axis and image plane intersect.\n",
    "\n",
    "<img src=\"img/lab04-15.gif\" width=\"600\"/>\n",
    "\n",
    "### Types of parameters\n",
    "\n",
    "There are two types of parameters to calculate to reconstruct the 3D structure of a scene from the pixel coordinates of image points:\n",
    "\n",
    "1. Extrinsic camera parameters: Parameters defining location and orientation of the camera reference frame in a world reference frame.\n",
    "2. Intrinsic camera parameters: Parameters linking 3D points in the camera reference frame to image points.\n",
    "\n",
    "<img src=\"img/lab04-17.png\" width=\"400\"/>\n",
    "\n",
    "<img src=\"img/lab04-16.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the figure shows, we can express a camera coordinate point in terms of a world coordinate using the intrinsic and extrinsic matrices as:\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} = \\begin{bmatrix}\n",
    "x \\\\\n",
    "y \\\\\n",
    "1\n",
    "\\end{bmatrix} \\propto \\mathtt{K} \\mathbf{X}_c = \\mathtt{K} \\begin{bmatrix} \\mathtt{R} \\mid \\mathbf{t} \\end{bmatrix} \\begin{bmatrix}\n",
    "X \\\\\n",
    "Y \\\\\n",
    "Z \\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Where\n",
    " - $\\mathbf{X}_c$ is a 3D camera point\n",
    " - $\\mathbf{X}_w = \\begin{bmatrix} X & Y & Z & 1 \\end{bmatrix}^\\top$ is a 3D world point in homogeneous form\n",
    " - $\\mathtt{K}$ is the intrinsic calibration matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extrinsic Camera Parameters\n",
    "\n",
    "The parameters $\\mathtt{R}$ and $\\mathbf{t}$ mean\n",
    "\n",
    "1. The origin of the world coordiante system in the camera reference frame.\n",
    "2. The rotation matrix that brings the corresponding axes of the two frames into alignment (i.e., onto each other).\n",
    "\n",
    "Using the extrinsic camera parameters, we can find the relation between the coordinates of a point P in world ($P_w$) and image plane ($P_{im}$) coordinates:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\propto \\mathtt{K}\\mathtt{R}(\\tilde{\\mathbf{X}}_w - \\mathbf{C}) = \\mathtt{K} \\begin{bmatrix} \\mathtt{R} \\mid \\mathbf{t} \\end{bmatrix} \\mathbf{X}_w,\n",
    "$$\n",
    "where\n",
    "\\begin{equation}\n",
    "[R | t] =\n",
    "\\begin{bmatrix}\n",
    "r_{11} & r_{12} & r_{13} & t_1\\\\\n",
    "r_{21} & r_{22} & r_{23} & t_2\\\\\n",
    "r_{31} & r_{32} & r_{33} & t_3\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "If \n",
    "$\\mathbf{X}_c =\n",
    "\\begin{bmatrix}\n",
    "X_c\\\\\n",
    "Y_c\\\\\n",
    "Z_c\n",
    "\\end{bmatrix}$ and \n",
    "$\\mathbf{X}_w =\n",
    "\\begin{bmatrix}\n",
    "X_w\\\\\n",
    "Y_w\\\\\n",
    "Z_w\\\\\n",
    "1,\n",
    "\\end{bmatrix}$\n",
    "then\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "X_c\\\\\n",
    "Y_c\\\\\n",
    "Z_c\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "r_{11} & r_{12} & r_{13} & t_1\\\\\n",
    "r_{21} & r_{22} & r_{23} & t_2\\\\\n",
    "r_{31} & r_{32} & r_{33} & t_3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "X_w\\\\\n",
    "Y_w\\\\\n",
    "Z_w\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intrinsic camera parameters\n",
    "\n",
    "These are the parameters that characterize the optical, geometric, and digital characteristics of the camera:\n",
    "1. Perspective projection (focal length $f$).\n",
    "2. The transformation between image plane coordinates and pixel coordinates.\n",
    "3. The geometric distortion introduced by lens optics.\n",
    "\n",
    "#### From Camera Coordinates to Image Plane Coordinates\n",
    "\n",
    "We apply the following perspective projection:\n",
    "\n",
    "$x = f\\frac{X_c}{Z_c}$, $y = f\\frac{X_c}{Z_c}$.\n",
    "\n",
    "#### From Image Plane Coordinates to Pixel coordinates\n",
    "\n",
    "<img src=\"img/lab04-18.png\" width=\"600\"/>\n",
    "\n",
    "In matrix notation:\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix} \\propto\n",
    "\\begin{bmatrix} x Z_c \\\\ y Z_c \\\\ Z_c \\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\\alpha_x & s & x_0\\\\\n",
    "0 & \\alpha_y & y_0\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "X_c\\\\\n",
    "Y_c\\\\\n",
    "Z_c\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "### From world coordinates to pixel coordinates\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix} \\propto\n",
    "\\begin{bmatrix} x Z_c \\\\ y Z_c \\\\ Z_c \\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "\\alpha_x & s & x_0\\\\\n",
    "0 & \\alpha_y & y_0\\\\\n",
    "0 & 0 & 1\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "r_{11} & r_{12} & r_{13} & t_1\\\\\n",
    "r_{21} & r_{22} & r_{23} & t_2\\\\\n",
    "r_{31} & r_{32} & r_{33} & t_3\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "X_w\\\\\n",
    "Y_w\\\\\n",
    "Z_w\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "Finally,\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix}\n",
    "x\\\\\n",
    "y\\\\\n",
    "1\n",
    "\\end{bmatrix} \\propto\n",
    "\\begin{bmatrix}\n",
    "m_{11} & m_{12} & m_{13} & m_{14}\\\\\n",
    "m_{21} & m_{22} & m_{23} & m_{24}\\\\\n",
    "m_{31} & m_{32} & m_{33} & m_{34}\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "X_w\\\\\n",
    "Y_w\\\\\n",
    "Z_w\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Distortion Due to Lens Optics\n",
    "\n",
    "As the image input might get curved by the lens, we must rectify pixel coordinates before\n",
    "attempting to calculate camera coordinate points using $\\mathtt{K}^{-1}$.\n",
    "We assume that $(x_d, y_d)$ is the pixel coordinate position of a point after distortion by the lens\n",
    "before rectifying the image. The parameters used in OpenCV are\n",
    "\\begin{equation}\n",
    "x = (x_d - x_c)(1+k_1r^2+k_2r^4 + k_3r^6)\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "y = (y_d-y_c)(1+k_1r^2+k_2r^4 + k_3r^6)\n",
    "\\end{equation}\n",
    "\n",
    "When $r^2 = (x_d - x_c)^2+(y_d - y_c)^2$, and $k_1$ and $k_2$ are intrinsic parameters.\n",
    "\n",
    "The presence of the radial distortion manifests in form of the \"barrel\" or \"fish-eye\" effect.\n",
    "\n",
    "Tangential distortion occurs because the image taking lenses are not perfectly parallel to the imaging plane. It can be represented via the formulas:\n",
    "\n",
    "\\begin{equation}\n",
    "x = x_d+(2p_1(x_d - x_c)(y_d - x_c) + p_2(r^2+2(x_d-x_c)^2))\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "y = y_d+(2p_1(r^2+2(y_d - y_c)^2)+2p_2(x_d - x_c)(y_d - y_c))\n",
    "\\end{equation}\n",
    "\n",
    "finally,\n",
    "\n",
    "\\begin{equation}\n",
    "x = x_d + (x_d - x_c)(1+k_1r^2+k_2r^4 + k_3r^6) +(2p_1(x_d - x_c)(y_d - x_c) + p_2(r^2+2(x_d-x_c)^2))\n",
    "\\end{equation}\n",
    "\\begin{equation}\n",
    "y = y_d + (y_d-y_c)(1+k_1r^2+k_2r^4 + k_3r^6) +(2p_1(r^2+2(y_d - y_c)^2)+2p_2(x_d - x_c)(y_d - y_c))\n",
    "\\end{equation}\n",
    "\n",
    "Thus we have 5 distortion parameters which in OpenCV are represented as a 5-element vector:\n",
    "\n",
    "\\begin{equation}\\mathbf{C} = \\begin{bmatrix}k1 & k2 & p1 & p2 & k3 \\end{bmatrix}^\\top\\end{equation}\n",
    "\n",
    "We can make C matrix by:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{bmatrix} x \\\\ y \\end{bmatrix} = \\mathtt{A} \\mathbf{C}'\n",
    "\\end{equation}\n",
    "\n",
    "Where $\\mathbf{C}'$ is\n",
    "\\begin{equation}\\mathbf{C}' = \\begin{bmatrix} k1 & k2 & p1 & p2 & k3 & 1\\end{bmatrix}\\end{equation}\n",
    "\n",
    "and $\\mathtt{A}$ is\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathtt{A} =\n",
    "\\begin{bmatrix}\n",
    "r^2(x_d-x_c) & r^4(x_d-x_c) & 2(x_d - x_c)(y_d - x_c) & (r^2+2(x_d-x_c)^2) & r^6(x_d-x_c) & (2x_d - x_c - x) \\\\\n",
    "r^2(y_d-y_c) & r^4(y_d-y_c) & (r^2+2(y_d-y_c)^2) & 2(x_d - x_c)(y_d - x_c) & r^6(y_d-y_c) & (2y_d - y_c - y)\n",
    "\\end{bmatrix}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Calibration\n",
    "\n",
    "The calibration process is explained by a flowchart given below.\n",
    "\n",
    "<img src=\"img/lab04-22.png\" width=\"400\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chessboard calibration\n",
    "\n",
    "#### 0. Firs of all, save and print the image (Chessboard) for use in camera.\n",
    "\n",
    "<img src=\"img/lab04-19.png\" width=\"600\"/>\n",
    "\n",
    "There are many patterns for calibration. However, openCV supports 3 patterns:\n",
    "- Classical black-white chessboard (Image above)\n",
    "- Symmetrical circle pattern\n",
    "\n",
    "<img src=\"img/lab04-21.png\" width=\"600\"/>\n",
    "\n",
    "- Asymmetrical circle pattern\n",
    "\n",
    "#### 1. Define real world coordinates with checkerboard pattern\n",
    "\n",
    "In the process of calibration we calculate the camera parameters by a set of know 3D points $(X_w, Y_w, Z_w)$ and their corresponding pixel location $(u,v)$ in the image.\n",
    "\n",
    "For the 3D points we photograph a checkerboard pattern with known dimensions at many different orientations. The world coordinate is attached to the checkerboard and since all the corner points lie on a plane, we can arbitrarily choose Z_w for every point to be 0. Since points are equally spaced in the checkerboard, the $(X_w, Y_w)$ coordinates of each 3D point are easily defined by taking one point as reference $(0, 0)$ and defining remaining with respect to that reference point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a program to get the image from camera or video.\n",
    "\n",
    "If you use web camera, code example is at below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <opencv2/opencv.hpp>\n",
    "#include <iostream>\n",
    "\n",
    "using namespace cv;\n",
    "using namespace std;\n",
    "int main()\n",
    "{\n",
    "    int frameAdd = 0;\n",
    "    Mat frame;\n",
    "    int iKey = -1;\n",
    "    //--- INITIALIZE VIDEOCAPTURE\n",
    "    VideoCapture cap;\n",
    "    // open the default camera using default API\n",
    "    // cap.open(0);\n",
    "    // OR advance usage: select any API backend\n",
    "    int deviceID = 0;             // 0 = open default camera\n",
    "    int apiID = cv::CAP_ANY;      // 0 = autodetect default API\n",
    "    // open selected camera using selected API\n",
    "    cap.open(deviceID, apiID);\n",
    "    // check if we succeeded\n",
    "    if (!cap.isOpened()) {\n",
    "        cerr << \"ERROR! Unable to open camera\\n\";\n",
    "        return -1;\n",
    "    }\n",
    "    //--- GRAB AND WRITE LOOP\n",
    "    cout << \"Start grabbing\" << endl\n",
    "        << \"Press s to save images and q to terminate\" << endl;\n",
    "    for (;;)\n",
    "    {\n",
    "        // wait for a new frame from camera and store it into 'frame'\n",
    "        cap.read(frame);\n",
    "        // check if we succeeded\n",
    "        if (frame.empty()) {\n",
    "            cerr << \"ERROR! blank frame grabbed\\n\";\n",
    "            break;\n",
    "        }\n",
    "        // show live and wait for a key with timeout long enough to show images\n",
    "        imshow(\"Live\", frame);\n",
    "        iKey = waitKey(5);\n",
    "        if (iKey == 's' || iKey == 'S')\n",
    "        {\n",
    "            imwrite(\"./images/frame\" + to_string(frameAdd) + \".jpg\", frame);\n",
    "            wantFrame[frameAdd] = frame.clone();\n",
    "            frameAdd++;\n",
    "            count << \"Frame: \" << frameAdd << \" has been saved.\" << endl;\n",
    "        }\n",
    "        else if (iKey == 'q' || iKey == 'Q')\n",
    "        {\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    // the camera will be deinitialized automatically in VideoCapture destructor\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "cap = cv2.VideoCapture()\n",
    "cap.open(0, cv2.CAP_ANY);\n",
    "if not cap.isOpened():\n",
    "    print(\"ERROR! Unable to open camera\\n\")\n",
    "    exit()\n",
    "print(\"Start grabbing\")\n",
    "print(\"Press s to save images and q to terminate\")\n",
    "frameAdd = 0\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    if frame is None:\n",
    "        print(\"ERROR! blank frame grabbed\\n\")\n",
    "        exit()\n",
    "    cv2.imshow(\"Live\", frame)\n",
    "    iKey = cv2.waitKey(5)\n",
    "    if iKey == ord('s') or iKey == ord('S'):\n",
    "        cv2.imwrite(\"./images/frame\" + str(frameAdd) + \".jpg\", frame)\n",
    "        frameAdd += 1\n",
    "        print(\"Frame: \", frameAdd, \" has been saved.\")\n",
    "    elif iKey == ord('q') or iKey == ord('Q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the web camera, you will see the camera with chessboard as below:\n",
    "\n",
    "<img src=\"img/lab04-20.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  2. Take several pictures for the checkerboard (generally more than 10)\n",
    "\n",
    "Save and put them to <code>./images</code>\n",
    "\n",
    "<img src=\"img/lab04-23.gif\" width=\"300\"/>\n",
    "\n",
    "There are two cases here\n",
    "\n",
    "    (1) To calibrate the distortion coefficient and camera internal parameters, the photographs need to contain a complete\n",
    "    chessboard, and at the same time require different distances, different orientations, and different tilt angles of the\n",
    "    chess board.\n",
    "\n",
    "    (2) Calibration distortion coefficient, camera internal parameters and camera external parameters. The picture contains\n",
    "    the above requirements. At the same time, each photo in the calibration program generated results will calculate an\n",
    "    external camera parameter. Therefore, according to actual needs, add a few photos of the chessboard at the working\n",
    "    position. (It is recommended to use the solvePnP function to obtain external camera parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 1. Find checkerboard corners\n",
    "\n",
    "OpenCV provides a builtin function called findChessboardCorners that looks for a checkerboard and returns the coordinates of the corners. Let’ see the usage in the code block below. Its usage is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool findChessboardCorners(InputArray image, \n",
    "                           Size patternSize, \n",
    "                           OutputArray corners, \n",
    "                           int flags=CALIB_CB_ADAPTIVE_THRESH+CALIB_CB_NORMALIZE_IMAGE );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retval, corners = cv2.findChessboardCorners(image, patternSize, flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Meaning |\n",
    "| :--- | :--- |\n",
    "| **image** | Source chessboard view. It must be an 8-bit grayscale or color image. |\n",
    "| **patternSize** | Number of inner corners per a chessboard row and column ( patternSize = cvSize (points_per_row, points_per_colum) = cvSize(columns,rows) ). |\n",
    "| **corners** | Output array of detected corners. |\n",
    "| **flags** | Various operation flags. You have to worry about these only when things do not work well. Go with the default. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  3. 2. Refine checkerboard corners\n",
    "\n",
    "Good calibration is all about precision. To get good results it is important to obtain the location of corners with sub-pixel level of accuracy.\n",
    "\n",
    "OpenCV’s function cornerSubPix takes in the original image, and the location of corners, and looks for the best corner location inside a small neighborhood of the original location. The algorithm is iterative in nature and therefore we need to specify the termination criteria ( e.g. number of iterations and/or the accuracy )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bool findChessboardCorners(InputArray image, \n",
    "                           Size patternSize,\n",
    "                           OutputArray corners,\n",
    "                           int flags = CALIB_CB_ADAPTIVE_THRESH + CALIB_CB_NORMALIZE_IMAGE );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retval, corners = cv2.findChessboardCorners(image, patternSize, flags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Meaning |\n",
    "| :--- | :--- |\n",
    "| **image** | Input image. |\n",
    "| **corners** | Initial coordinates of the input corners and refined coordinates provided for output. |\n",
    "| **winSize** | Half of the side length of the search window. |\n",
    "| **zeroZone** | Half of the size of the dead region in the middle of the search zone over which the summation in the formula below is not done. It is used sometimes to avoid possible singularities of the autocorrelation matrix. The value of (-1,-1) indicates that there is no such a size. |\n",
    "|**criteria** | Criteria for termination of the iterative process of corner refinement. That is, the process of corner position refinement stops either after criteria.maxCount iterations or when the corner position moves by less than criteria.epsilon on some iteration.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Calibrate Camera\n",
    "\n",
    "The final step of calibration is to pass the 3D points in world coordinates and their 2D locations in all images to OpenCV’s calibrateCamera method. The implementation is based on a paper by Zhengyou Zhang. The math is a bit involved and requires a background in linear algebra.\n",
    "\n",
    "Let’s look at the syntax for calibrateCamera"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "double calibrateCamera(InputArrayOfArrays objectPoints,\n",
    "                       InputArrayOfArrays imagePoints,\n",
    "                       Size imageSize,\n",
    "                       InputOutputArray cameraMatrix,\n",
    "                       InputOutputArray distCoeffs,\n",
    "                       OutputArrayOfArrays rvecs,\n",
    "                       OutputArrayOfArrays tvecs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retval, cameraMatrix, distCoeffs, rvecs, tvecs = cv2.calibrateCamera(objectPoints, imagePoints, imageSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Variable | Meaning |\n",
    "| :--- | :--- |\n",
    "| **objectPoints** | A vector of vector of 3D points. The outer vector contains as many elements as the number of the pattern views. |\n",
    "| **imagePoints** | A vector of vectors of the 2D image points. |\n",
    "| **imageSize** | Size of the image |\n",
    "| **cameraMatrix** | Intrinsic camera matrix |\n",
    "|**distCoeffs** | Lens distortion coefficients. These coefficients will be explained in a future post.|\n",
    "| **rvecs** | Rotation specified as a 3×1 vector. The direction of the vector specifies the axis of rotation and the magnitude of the vector specifies the angle of rotation. |\n",
    "| **tvecs** | 3×1 Translation vector. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full code of camera calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <opencv2/opencv.hpp>\n",
    "#include <opencv2/calib3d/calib3d.hpp>\n",
    "#include <opencv2/highgui/highgui.hpp>\n",
    "#include <opencv2/imgproc/imgproc.hpp>\n",
    "#include <stdio.h>\n",
    "#include <iostream>\n",
    "\n",
    "// Defining the dimensions of checkerboard\n",
    "int CHECKERBOARD[2]{8,11}; // width, height\n",
    "\n",
    "int main()\n",
    "{\n",
    "  // Creating vector to store vectors of 3D points for each checkerboard image\n",
    "  std::vector<std::vector<cv::Point3f> > objpoints;\n",
    "\n",
    "  // Creating vector to store vectors of 2D points for each checkerboard image\n",
    "  std::vector<std::vector<cv::Point2f> > imgpoints;\n",
    "\n",
    "  // Defining the world coordinates for 3D points\n",
    "  std::vector<cv::Point3f> objp;\n",
    "  for(int i = 0; i<CHECKERBOARD[1]; i++)\n",
    "  {\n",
    "    for(int j = 0; j<CHECKERBOARD[0]; j++)\n",
    "      objp.push_back(cv::Point3f(j,i,0));\n",
    "  }\n",
    "\n",
    "\n",
    "  // Extracting path of individual image stored in a given directory\n",
    "  std::vector<cv::String> images;\n",
    "  // Path of the folder containing checkerboard images\n",
    "  std::string path = \"./images/*.jpg\";\n",
    "\n",
    "  cv::glob(path, images);\n",
    "\n",
    "  cv::Mat frame, gray;\n",
    "  // vector to store the pixel coordinates of detected checker board corners \n",
    "  std::vector<cv::Point2f> corner_pts;\n",
    "  bool success;\n",
    "\n",
    "  // Looping over all the images in the directory\n",
    "  for(int i{0}; i<images.size(); i++)\n",
    "  {\n",
    "    frame = cv::imread(images[i]);\n",
    "    cv::cvtColor(frame,gray,cv::COLOR_BGR2GRAY);\n",
    "\n",
    "    // Finding checker board corners\n",
    "    // If desired number of corners are found in the image then success = true  \n",
    "    success = cv::findChessboardCorners(gray, cv::Size(CHECKERBOARD[0], CHECKERBOARD[1]), corner_pts, CV_CALIB_CB_ADAPTIVE_THRESH | CV_CALIB_CB_FAST_CHECK | CV_CALIB_CB_NORMALIZE_IMAGE);\n",
    "    \n",
    "    /* \n",
    "     * If desired number of corner are detected,\n",
    "     * we refine the pixel coordinates and display \n",
    "     * them on the images of checker board\n",
    "    */\n",
    "    if(success)\n",
    "    {\n",
    "      cv::TermCriteria criteria(CV_TERMCRIT_EPS | CV_TERMCRIT_ITER, 30, 0.001);\n",
    "      \n",
    "      // refining pixel coordinates for given 2d points.\n",
    "      cv::cornerSubPix(gray,corner_pts,cv::Size(11,11), cv::Size(-1,-1),criteria);\n",
    "      \n",
    "      // Displaying the detected corner points on the checker board\n",
    "      cv::drawChessboardCorners(frame, cv::Size(CHECKERBOARD[0], CHECKERBOARD[1]), corner_pts, success);\n",
    "      \n",
    "      objpoints.push_back(objp);\n",
    "      imgpoints.push_back(corner_pts);\n",
    "    }\n",
    "\n",
    "    cv::imshow(\"Image\",frame);\n",
    "    cv::waitKey(0);\n",
    "  }\n",
    "\n",
    "  cv::destroyAllWindows();\n",
    "\n",
    "  cv::Mat cameraMatrix,distCoeffs,R,T;\n",
    "\n",
    "  /*\n",
    "   * Performing camera calibration by \n",
    "   * passing the value of known 3D points (objpoints)\n",
    "   * and corresponding pixel coordinates of the \n",
    "   * detected corners (imgpoints)\n",
    "  */\n",
    "  cv::calibrateCamera(objpoints, imgpoints, cv::Size(gray.rows,gray.cols), cameraMatrix, distCoeffs, R, T);\n",
    "\n",
    "  std::cout << \"cameraMatrix : \" << cameraMatrix << std::endl;\n",
    "  std::cout << \"distCoeffs : \" << distCoeffs << std::endl;\n",
    "  std::cout << \"Rotation vector : \" << R << std::endl;\n",
    "  std::cout << \"Translation vector : \" << T << std::endl;\n",
    "\n",
    "  return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Defining the dimensions of checkerboard\n",
    "CHECKERBOARD = (8,11)\n",
    "criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "# Creating vector to store vectors of 3D points for each checkerboard image\n",
    "objpoints = []\n",
    "# Creating vector to store vectors of 2D points for each checkerboard image\n",
    "imgpoints = [] \n",
    "\n",
    "\n",
    "# Defining the world coordinates for 3D points\n",
    "objp = np.zeros((1, CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "prev_img_shape = None\n",
    "\n",
    "# Extracting path of individual image stored in a given directory\n",
    "images = glob.glob('./images/*.jpg')\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chess board corners\n",
    "    # If desired number of corners are found in the image then ret = true\n",
    "    ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "    \n",
    "    \"\"\"\n",
    "    If desired number of corner are detected,\n",
    "    we refine the pixel coordinates and display \n",
    "    them on the images of checker board\n",
    "    \"\"\"\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        # refining pixel coordinates for given 2d points.\n",
    "        corners2 = cv2.cornerSubPix(gray, corners, (11,11),(-1,-1), criteria)\n",
    "        \n",
    "        imgpoints.append(corners2)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        img = cv2.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)\n",
    "    \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "h,w = img.shape[:2]\n",
    "\n",
    "\"\"\"\n",
    "Performing camera calibration by \n",
    "passing the value of known 3D points (objpoints)\n",
    "and corresponding pixel coordinates of the \n",
    "detected corners (imgpoints)\n",
    "\"\"\"\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "print(\"Camera matrix : \\n\")\n",
    "print(mtx)\n",
    "print(\"dist : \\n\")\n",
    "print(dist)\n",
    "print(\"rvecs : \\n\")\n",
    "print(rvecs)\n",
    "print(\"tvecs : \\n\")\n",
    "print(tvecs)\n",
    "\n",
    "# Show images of undistorted\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    res = cv2.undistort(img, mtx, dist)\n",
    "    cv2.imshow('img',img)\n",
    "    cv2.imshow('res',res)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result of the images\n",
    "\n",
    "You can see the result like this.\n",
    "\n",
    "Source image\n",
    "<img src=\"img/lab04-26.png\" width=\"600\"/>\n",
    "\n",
    "Chessboard detection\n",
    "<img src=\"img/lab04-24.png\" width=\"600\"/>\n",
    "\n",
    "Rectified image\n",
    "<img src=\"img/lab04-25.png\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More fancier in undistorted\n",
    "\n",
    "After undistorted, the result of rectified image may need to be crops."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way 1: This is the easiest way. Just call the function and use ROI obtained above to crop the result.\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    \n",
    "    res = cv2.undistort(img, mtx, dist)\n",
    "    \n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    res = res[y:y+h, x:x+w]\n",
    "    \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.imshow('res',res)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Way 2: This way is a little bit more difficult. \n",
    "# First, find a mapping function from the distorted image to the undistorted image.\n",
    "# Then use the remap function.\n",
    "\n",
    "for fname in images:\n",
    "    img = cv2.imread(fname)\n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    \n",
    "    mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "    res = cv2.remap(img, mapx, mapy, cv.INTER_LINEAR)\n",
    "    \n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    res = res[y:y+h, x:x+w]\n",
    "    \n",
    "    cv2.imshow('img',img)\n",
    "    cv2.imshow('res',res)\n",
    "    cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-projection Error\n",
    "\n",
    "Re-projection error gives a good estimation of just how exact the found parameters are. The closer the re-projection error is to zero, the more accurate the parameters we found are. Given the intrinsic, distortion, rotation and translation matrices, we must first transform the object point to image point using **cv.projectPoints()**. Then, we can calculate the absolute norm between what we got with our transformation and the corner finding algorithm. To find the average error, we calculate the arithmetical mean of the errors calculated for all the calibration images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = 0\n",
    "for i in range(len(objpoints)):\n",
    "    imgpoints2, _ = cv.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "    error = cv.norm(imgpoints[i], imgpoints2, cv.NORM_L2)/len(imgpoints2)\n",
    "    mean_error += error\n",
    "print( \"total error: {}\".format(mean_error/len(objpoints)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save calibration file\n",
    "\n",
    "As the result, save the calibration file into yml file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full code of Calibration from scratch\n",
    "\n",
    "Please look at https://github.com/opencv/opencv/blob/master/samples/cpp/tutorial_code/calib3d/camera_calibration/camera_calibration.cpp\n",
    "There is the source code in C++ from scratch. It may useful when you need to write it as commercial product."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#include <iostream>\n",
    "#include <sstream>\n",
    "#include <string>\n",
    "#include <ctime>\n",
    "#include <cstdio>\n",
    "\n",
    "#include <opencv2/core.hpp>\n",
    "#include <opencv2/core/utility.hpp>\n",
    "#include <opencv2/imgproc.hpp>\n",
    "#include <opencv2/calib3d.hpp>\n",
    "#include <opencv2/imgcodecs.hpp>\n",
    "#include <opencv2/videoio.hpp>\n",
    "#include <opencv2/highgui.hpp>\n",
    "\n",
    "using namespace cv;\n",
    "using namespace std;\n",
    "\n",
    "class Settings\n",
    "{\n",
    "public:\n",
    "    Settings() : goodInput(false) {}\n",
    "    enum Pattern { NOT_EXISTING, CHESSBOARD, CIRCLES_GRID, ASYMMETRIC_CIRCLES_GRID };\n",
    "    enum InputType { INVALID, CAMERA, VIDEO_FILE, IMAGE_LIST };\n",
    "\n",
    "    void write(FileStorage& fs) const                        //Write serialization for this class\n",
    "    {\n",
    "        fs << \"{\"\n",
    "                  << \"BoardSize_Width\"  << boardSize.width\n",
    "                  << \"BoardSize_Height\" << boardSize.height\n",
    "                  << \"Square_Size\"         << squareSize\n",
    "                  << \"Calibrate_Pattern\" << patternToUse\n",
    "                  << \"Calibrate_NrOfFrameToUse\" << nrFrames\n",
    "                  << \"Calibrate_FixAspectRatio\" << aspectRatio\n",
    "                  << \"Calibrate_AssumeZeroTangentialDistortion\" << calibZeroTangentDist\n",
    "                  << \"Calibrate_FixPrincipalPointAtTheCenter\" << calibFixPrincipalPoint\n",
    "\n",
    "                  << \"Write_DetectedFeaturePoints\" << writePoints\n",
    "                  << \"Write_extrinsicParameters\"   << writeExtrinsics\n",
    "                  << \"Write_gridPoints\" << writeGrid\n",
    "                  << \"Write_outputFileName\"  << outputFileName\n",
    "\n",
    "                  << \"Show_UndistortedImage\" << showUndistorted\n",
    "\n",
    "                  << \"Input_FlipAroundHorizontalAxis\" << flipVertical\n",
    "                  << \"Input_Delay\" << delay\n",
    "                  << \"Input\" << input\n",
    "           << \"}\";\n",
    "    }\n",
    "    void read(const FileNode& node)                          //Read serialization for this class\n",
    "    {\n",
    "        node[\"BoardSize_Width\" ] >> boardSize.width;\n",
    "        node[\"BoardSize_Height\"] >> boardSize.height;\n",
    "        node[\"Calibrate_Pattern\"] >> patternToUse;\n",
    "        node[\"Square_Size\"]  >> squareSize;\n",
    "        node[\"Calibrate_NrOfFrameToUse\"] >> nrFrames;\n",
    "        node[\"Calibrate_FixAspectRatio\"] >> aspectRatio;\n",
    "        node[\"Write_DetectedFeaturePoints\"] >> writePoints;\n",
    "        node[\"Write_extrinsicParameters\"] >> writeExtrinsics;\n",
    "        node[\"Write_gridPoints\"] >> writeGrid;\n",
    "        node[\"Write_outputFileName\"] >> outputFileName;\n",
    "        node[\"Calibrate_AssumeZeroTangentialDistortion\"] >> calibZeroTangentDist;\n",
    "        node[\"Calibrate_FixPrincipalPointAtTheCenter\"] >> calibFixPrincipalPoint;\n",
    "        node[\"Calibrate_UseFisheyeModel\"] >> useFisheye;\n",
    "        node[\"Input_FlipAroundHorizontalAxis\"] >> flipVertical;\n",
    "        node[\"Show_UndistortedImage\"] >> showUndistorted;\n",
    "        node[\"Input\"] >> input;\n",
    "        node[\"Input_Delay\"] >> delay;\n",
    "        node[\"Fix_K1\"] >> fixK1;\n",
    "        node[\"Fix_K2\"] >> fixK2;\n",
    "        node[\"Fix_K3\"] >> fixK3;\n",
    "        node[\"Fix_K4\"] >> fixK4;\n",
    "        node[\"Fix_K5\"] >> fixK5;\n",
    "\n",
    "        validate();\n",
    "    }\n",
    "    void validate()\n",
    "    {\n",
    "        goodInput = true;\n",
    "        if (boardSize.width <= 0 || boardSize.height <= 0)\n",
    "        {\n",
    "            cerr << \"Invalid Board size: \" << boardSize.width << \" \" << boardSize.height << endl;\n",
    "            goodInput = false;\n",
    "        }\n",
    "        if (squareSize <= 10e-6)\n",
    "        {\n",
    "            cerr << \"Invalid square size \" << squareSize << endl;\n",
    "            goodInput = false;\n",
    "        }\n",
    "        if (nrFrames <= 0)\n",
    "        {\n",
    "            cerr << \"Invalid number of frames \" << nrFrames << endl;\n",
    "            goodInput = false;\n",
    "        }\n",
    "\n",
    "        if (input.empty())      // Check for valid input\n",
    "                inputType = INVALID;\n",
    "        else\n",
    "        {\n",
    "            if (input[0] >= '0' && input[0] <= '9')\n",
    "            {\n",
    "                stringstream ss(input);\n",
    "                ss >> cameraID;\n",
    "                inputType = CAMERA;\n",
    "            }\n",
    "            else\n",
    "            {\n",
    "                if (isListOfImages(input) && readStringList(input, imageList))\n",
    "                {\n",
    "                    inputType = IMAGE_LIST;\n",
    "                    nrFrames = (nrFrames < (int)imageList.size()) ? nrFrames : (int)imageList.size();\n",
    "                }\n",
    "                else\n",
    "                    inputType = VIDEO_FILE;\n",
    "            }\n",
    "            if (inputType == CAMERA)\n",
    "                inputCapture.open(cameraID);\n",
    "            if (inputType == VIDEO_FILE)\n",
    "                inputCapture.open(input);\n",
    "            if (inputType != IMAGE_LIST && !inputCapture.isOpened())\n",
    "                    inputType = INVALID;\n",
    "        }\n",
    "        if (inputType == INVALID)\n",
    "        {\n",
    "            cerr << \" Input does not exist: \" << input;\n",
    "            goodInput = false;\n",
    "        }\n",
    "\n",
    "        flag = 0;\n",
    "        if(calibFixPrincipalPoint) flag |= CALIB_FIX_PRINCIPAL_POINT;\n",
    "        if(calibZeroTangentDist)   flag |= CALIB_ZERO_TANGENT_DIST;\n",
    "        if(aspectRatio)            flag |= CALIB_FIX_ASPECT_RATIO;\n",
    "        if(fixK1)                  flag |= CALIB_FIX_K1;\n",
    "        if(fixK2)                  flag |= CALIB_FIX_K2;\n",
    "        if(fixK3)                  flag |= CALIB_FIX_K3;\n",
    "        if(fixK4)                  flag |= CALIB_FIX_K4;\n",
    "        if(fixK5)                  flag |= CALIB_FIX_K5;\n",
    "\n",
    "        if (useFisheye) {\n",
    "            // the fisheye model has its own enum, so overwrite the flags\n",
    "            flag = fisheye::CALIB_FIX_SKEW | fisheye::CALIB_RECOMPUTE_EXTRINSIC;\n",
    "            if(fixK1)                   flag |= fisheye::CALIB_FIX_K1;\n",
    "            if(fixK2)                   flag |= fisheye::CALIB_FIX_K2;\n",
    "            if(fixK3)                   flag |= fisheye::CALIB_FIX_K3;\n",
    "            if(fixK4)                   flag |= fisheye::CALIB_FIX_K4;\n",
    "            if (calibFixPrincipalPoint) flag |= fisheye::CALIB_FIX_PRINCIPAL_POINT;\n",
    "        }\n",
    "\n",
    "        calibrationPattern = NOT_EXISTING;\n",
    "        if (!patternToUse.compare(\"CHESSBOARD\")) calibrationPattern = CHESSBOARD;\n",
    "        if (!patternToUse.compare(\"CIRCLES_GRID\")) calibrationPattern = CIRCLES_GRID;\n",
    "        if (!patternToUse.compare(\"ASYMMETRIC_CIRCLES_GRID\")) calibrationPattern = ASYMMETRIC_CIRCLES_GRID;\n",
    "        if (calibrationPattern == NOT_EXISTING)\n",
    "        {\n",
    "            cerr << \" Camera calibration mode does not exist: \" << patternToUse << endl;\n",
    "            goodInput = false;\n",
    "        }\n",
    "        atImageList = 0;\n",
    "\n",
    "    }\n",
    "    Mat nextImage()\n",
    "    {\n",
    "        Mat result;\n",
    "        if( inputCapture.isOpened() )\n",
    "        {\n",
    "            Mat view0;\n",
    "            inputCapture >> view0;\n",
    "            view0.copyTo(result);\n",
    "        }\n",
    "        else if( atImageList < imageList.size() )\n",
    "            result = imread(imageList[atImageList++], IMREAD_COLOR);\n",
    "\n",
    "        return result;\n",
    "    }\n",
    "\n",
    "    static bool readStringList( const string& filename, vector<string>& l )\n",
    "    {\n",
    "        l.clear();\n",
    "        FileStorage fs(filename, FileStorage::READ);\n",
    "        if( !fs.isOpened() )\n",
    "            return false;\n",
    "        FileNode n = fs.getFirstTopLevelNode();\n",
    "        if( n.type() != FileNode::SEQ )\n",
    "            return false;\n",
    "        FileNodeIterator it = n.begin(), it_end = n.end();\n",
    "        for( ; it != it_end; ++it )\n",
    "            l.push_back((string)*it);\n",
    "        return true;\n",
    "    }\n",
    "\n",
    "    static bool isListOfImages( const string& filename)\n",
    "    {\n",
    "        string s(filename);\n",
    "        // Look for file extension\n",
    "        if( s.find(\".xml\") == string::npos && s.find(\".yaml\") == string::npos && s.find(\".yml\") == string::npos )\n",
    "            return false;\n",
    "        else\n",
    "            return true;\n",
    "    }\n",
    "public:\n",
    "    Size boardSize;              // The size of the board -> Number of items by width and height\n",
    "    Pattern calibrationPattern;  // One of the Chessboard, circles, or asymmetric circle pattern\n",
    "    float squareSize;            // The size of a square in your defined unit (point, millimeter,etc).\n",
    "    int nrFrames;                // The number of frames to use from the input for calibration\n",
    "    float aspectRatio;           // The aspect ratio\n",
    "    int delay;                   // In case of a video input\n",
    "    bool writePoints;            // Write detected feature points\n",
    "    bool writeExtrinsics;        // Write extrinsic parameters\n",
    "    bool writeGrid;              // Write refined 3D target grid points\n",
    "    bool calibZeroTangentDist;   // Assume zero tangential distortion\n",
    "    bool calibFixPrincipalPoint; // Fix the principal point at the center\n",
    "    bool flipVertical;           // Flip the captured images around the horizontal axis\n",
    "    string outputFileName;       // The name of the file where to write\n",
    "    bool showUndistorted;        // Show undistorted images after calibration\n",
    "    string input;                // The input ->\n",
    "    bool useFisheye;             // use fisheye camera model for calibration\n",
    "    bool fixK1;                  // fix K1 distortion coefficient\n",
    "    bool fixK2;                  // fix K2 distortion coefficient\n",
    "    bool fixK3;                  // fix K3 distortion coefficient\n",
    "    bool fixK4;                  // fix K4 distortion coefficient\n",
    "    bool fixK5;                  // fix K5 distortion coefficient\n",
    "\n",
    "    int cameraID;\n",
    "    vector<string> imageList;\n",
    "    size_t atImageList;\n",
    "    VideoCapture inputCapture;\n",
    "    InputType inputType;\n",
    "    bool goodInput;\n",
    "    int flag;\n",
    "\n",
    "private:\n",
    "    string patternToUse;\n",
    "\n",
    "\n",
    "};\n",
    "\n",
    "static inline void read(const FileNode& node, Settings& x, const Settings& default_value = Settings())\n",
    "{\n",
    "    if(node.empty())\n",
    "        x = default_value;\n",
    "    else\n",
    "        x.read(node);\n",
    "}\n",
    "\n",
    "enum { DETECTION = 0, CAPTURING = 1, CALIBRATED = 2 };\n",
    "\n",
    "bool runCalibrationAndSave(Settings& s, Size imageSize, Mat&  cameraMatrix, Mat& distCoeffs,\n",
    "                           vector<vector<Point2f> > imagePoints, float grid_width, bool release_object);\n",
    "\n",
    "int main(int argc, char* argv[])\n",
    "{\n",
    "    const String keys\n",
    "        = \"{help h usage ? |           | print this message            }\"\n",
    "          \"{@settings      |default.xml| input setting file            }\"\n",
    "          \"{d              |           | actual distance between top-left and top-right corners of \"\n",
    "          \"the calibration grid }\"\n",
    "          \"{winSize        | 11        | Half of search window for cornerSubPix }\";\n",
    "    CommandLineParser parser(argc, argv, keys);\n",
    "    parser.about(\"This is a camera calibration sample.\\n\"\n",
    "                 \"Usage: camera_calibration [configuration_file -- default ./default.xml]\\n\"\n",
    "                 \"Near the sample file you'll find the configuration file, which has detailed help of \"\n",
    "                 \"how to edit it. It may be any OpenCV supported file format XML/YAML.\");\n",
    "    if (!parser.check()) {\n",
    "        parser.printErrors();\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "    if (parser.has(\"help\")) {\n",
    "        parser.printMessage();\n",
    "        return 0;\n",
    "    }\n",
    "\n",
    "    //! [file_read]\n",
    "    Settings s;\n",
    "    const string inputSettingsFile = parser.get<string>(0);\n",
    "    FileStorage fs(inputSettingsFile, FileStorage::READ); // Read the settings\n",
    "    if (!fs.isOpened())\n",
    "    {\n",
    "        cout << \"Could not open the configuration file: \\\"\" << inputSettingsFile << \"\\\"\" << endl;\n",
    "        parser.printMessage();\n",
    "        return -1;\n",
    "    }\n",
    "    fs[\"Settings\"] >> s;\n",
    "    fs.release();                                         // close Settings file\n",
    "    //! [file_read]\n",
    "\n",
    "    //FileStorage fout(\"settings.yml\", FileStorage::WRITE); // write config as YAML\n",
    "    //fout << \"Settings\" << s;\n",
    "\n",
    "    if (!s.goodInput)\n",
    "    {\n",
    "        cout << \"Invalid input detected. Application stopping. \" << endl;\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    int winSize = parser.get<int>(\"winSize\");\n",
    "\n",
    "    float grid_width = s.squareSize * (s.boardSize.width - 1);\n",
    "    bool release_object = false;\n",
    "    if (parser.has(\"d\")) {\n",
    "        grid_width = parser.get<float>(\"d\");\n",
    "        release_object = true;\n",
    "    }\n",
    "\n",
    "    vector<vector<Point2f> > imagePoints;\n",
    "    Mat cameraMatrix, distCoeffs;\n",
    "    Size imageSize;\n",
    "    int mode = s.inputType == Settings::IMAGE_LIST ? CAPTURING : DETECTION;\n",
    "    clock_t prevTimestamp = 0;\n",
    "    const Scalar RED(0,0,255), GREEN(0,255,0);\n",
    "    const char ESC_KEY = 27;\n",
    "\n",
    "    //! [get_input]\n",
    "    for(;;)\n",
    "    {\n",
    "        Mat view;\n",
    "        bool blinkOutput = false;\n",
    "\n",
    "        view = s.nextImage();\n",
    "\n",
    "        //-----  If no more image, or got enough, then stop calibration and show result -------------\n",
    "        if( mode == CAPTURING && imagePoints.size() >= (size_t)s.nrFrames )\n",
    "        {\n",
    "          if(runCalibrationAndSave(s, imageSize,  cameraMatrix, distCoeffs, imagePoints, grid_width,\n",
    "                                   release_object))\n",
    "              mode = CALIBRATED;\n",
    "          else\n",
    "              mode = DETECTION;\n",
    "        }\n",
    "        if(view.empty())          // If there are no more images stop the loop\n",
    "        {\n",
    "            // if calibration threshold was not reached yet, calibrate now\n",
    "            if( mode != CALIBRATED && !imagePoints.empty() )\n",
    "                runCalibrationAndSave(s, imageSize,  cameraMatrix, distCoeffs, imagePoints, grid_width,\n",
    "                                      release_object);\n",
    "            break;\n",
    "        }\n",
    "        //! [get_input]\n",
    "\n",
    "        imageSize = view.size();  // Format input image.\n",
    "        if( s.flipVertical )    flip( view, view, 0 );\n",
    "\n",
    "        //! [find_pattern]\n",
    "        vector<Point2f> pointBuf;\n",
    "\n",
    "        bool found;\n",
    "\n",
    "        int chessBoardFlags = CALIB_CB_ADAPTIVE_THRESH | CALIB_CB_NORMALIZE_IMAGE;\n",
    "\n",
    "        if(!s.useFisheye) {\n",
    "            // fast check erroneously fails with high distortions like fisheye\n",
    "            chessBoardFlags |= CALIB_CB_FAST_CHECK;\n",
    "        }\n",
    "\n",
    "        switch( s.calibrationPattern ) // Find feature points on the input format\n",
    "        {\n",
    "        case Settings::CHESSBOARD:\n",
    "            found = findChessboardCorners( view, s.boardSize, pointBuf, chessBoardFlags);\n",
    "            break;\n",
    "        case Settings::CIRCLES_GRID:\n",
    "            found = findCirclesGrid( view, s.boardSize, pointBuf );\n",
    "            break;\n",
    "        case Settings::ASYMMETRIC_CIRCLES_GRID:\n",
    "            found = findCirclesGrid( view, s.boardSize, pointBuf, CALIB_CB_ASYMMETRIC_GRID );\n",
    "            break;\n",
    "        default:\n",
    "            found = false;\n",
    "            break;\n",
    "        }\n",
    "        //! [find_pattern]\n",
    "        //! [pattern_found]\n",
    "        if ( found)                // If done with success,\n",
    "        {\n",
    "              // improve the found corners' coordinate accuracy for chessboard\n",
    "                if( s.calibrationPattern == Settings::CHESSBOARD)\n",
    "                {\n",
    "                    Mat viewGray;\n",
    "                    cvtColor(view, viewGray, COLOR_BGR2GRAY);\n",
    "                    cornerSubPix( viewGray, pointBuf, Size(winSize,winSize),\n",
    "                        Size(-1,-1), TermCriteria( TermCriteria::EPS+TermCriteria::COUNT, 30, 0.0001 ));\n",
    "                }\n",
    "\n",
    "                if( mode == CAPTURING &&  // For camera only take new samples after delay time\n",
    "                    (!s.inputCapture.isOpened() || clock() - prevTimestamp > s.delay*1e-3*CLOCKS_PER_SEC) )\n",
    "                {\n",
    "                    imagePoints.push_back(pointBuf);\n",
    "                    prevTimestamp = clock();\n",
    "                    blinkOutput = s.inputCapture.isOpened();\n",
    "                }\n",
    "\n",
    "                // Draw the corners.\n",
    "                drawChessboardCorners( view, s.boardSize, Mat(pointBuf), found );\n",
    "        }\n",
    "        //! [pattern_found]\n",
    "        //----------------------------- Output Text ------------------------------------------------\n",
    "        //! [output_text]\n",
    "        string msg = (mode == CAPTURING) ? \"100/100\" :\n",
    "                      mode == CALIBRATED ? \"Calibrated\" : \"Press 'g' to start\";\n",
    "        int baseLine = 0;\n",
    "        Size textSize = getTextSize(msg, 1, 1, 1, &baseLine);\n",
    "        Point textOrigin(view.cols - 2*textSize.width - 10, view.rows - 2*baseLine - 10);\n",
    "\n",
    "        if( mode == CAPTURING )\n",
    "        {\n",
    "            if(s.showUndistorted)\n",
    "                msg = cv::format( \"%d/%d Undist\", (int)imagePoints.size(), s.nrFrames );\n",
    "            else\n",
    "                msg = cv::format( \"%d/%d\", (int)imagePoints.size(), s.nrFrames );\n",
    "        }\n",
    "\n",
    "        putText( view, msg, textOrigin, 1, 1, mode == CALIBRATED ?  GREEN : RED);\n",
    "\n",
    "        if( blinkOutput )\n",
    "            bitwise_not(view, view);\n",
    "        //! [output_text]\n",
    "        //------------------------- Video capture  output  undistorted ------------------------------\n",
    "        //! [output_undistorted]\n",
    "        if( mode == CALIBRATED && s.showUndistorted )\n",
    "        {\n",
    "            Mat temp = view.clone();\n",
    "            if (s.useFisheye)\n",
    "            {\n",
    "                Mat newCamMat;\n",
    "                fisheye::estimateNewCameraMatrixForUndistortRectify(cameraMatrix, distCoeffs, imageSize,\n",
    "                                                                    Matx33d::eye(), newCamMat, 1);\n",
    "                cv::fisheye::undistortImage(temp, view, cameraMatrix, distCoeffs, newCamMat);\n",
    "            }\n",
    "            else\n",
    "              undistort(temp, view, cameraMatrix, distCoeffs);\n",
    "        }\n",
    "        //! [output_undistorted]\n",
    "        //------------------------------ Show image and check for input commands -------------------\n",
    "        //! [await_input]\n",
    "        imshow(\"Image View\", view);\n",
    "        char key = (char)waitKey(s.inputCapture.isOpened() ? 50 : s.delay);\n",
    "\n",
    "        if( key  == ESC_KEY )\n",
    "            break;\n",
    "\n",
    "        if( key == 'u' && mode == CALIBRATED )\n",
    "           s.showUndistorted = !s.showUndistorted;\n",
    "\n",
    "        if( s.inputCapture.isOpened() && key == 'g' )\n",
    "        {\n",
    "            mode = CAPTURING;\n",
    "            imagePoints.clear();\n",
    "        }\n",
    "        //! [await_input]\n",
    "    }\n",
    "\n",
    "    // -----------------------Show the undistorted image for the image list ------------------------\n",
    "    //! [show_results]\n",
    "    if( s.inputType == Settings::IMAGE_LIST && s.showUndistorted && !cameraMatrix.empty())\n",
    "    {\n",
    "        Mat view, rview, map1, map2;\n",
    "\n",
    "        if (s.useFisheye)\n",
    "        {\n",
    "            Mat newCamMat;\n",
    "            fisheye::estimateNewCameraMatrixForUndistortRectify(cameraMatrix, distCoeffs, imageSize,\n",
    "                                                                Matx33d::eye(), newCamMat, 1);\n",
    "            fisheye::initUndistortRectifyMap(cameraMatrix, distCoeffs, Matx33d::eye(), newCamMat, imageSize,\n",
    "                                             CV_16SC2, map1, map2);\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            initUndistortRectifyMap(\n",
    "                cameraMatrix, distCoeffs, Mat(),\n",
    "                getOptimalNewCameraMatrix(cameraMatrix, distCoeffs, imageSize, 1, imageSize, 0), imageSize,\n",
    "                CV_16SC2, map1, map2);\n",
    "        }\n",
    "\n",
    "        for(size_t i = 0; i < s.imageList.size(); i++ )\n",
    "        {\n",
    "            view = imread(s.imageList[i], IMREAD_COLOR);\n",
    "            if(view.empty())\n",
    "                continue;\n",
    "            remap(view, rview, map1, map2, INTER_LINEAR);\n",
    "            imshow(\"Image View\", rview);\n",
    "            char c = (char)waitKey();\n",
    "            if( c  == ESC_KEY || c == 'q' || c == 'Q' )\n",
    "                break;\n",
    "        }\n",
    "    }\n",
    "    //! [show_results]\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "//! [compute_errors]\n",
    "static double computeReprojectionErrors( const vector<vector<Point3f> >& objectPoints,\n",
    "                                         const vector<vector<Point2f> >& imagePoints,\n",
    "                                         const vector<Mat>& rvecs, const vector<Mat>& tvecs,\n",
    "                                         const Mat& cameraMatrix , const Mat& distCoeffs,\n",
    "                                         vector<float>& perViewErrors, bool fisheye)\n",
    "{\n",
    "    vector<Point2f> imagePoints2;\n",
    "    size_t totalPoints = 0;\n",
    "    double totalErr = 0, err;\n",
    "    perViewErrors.resize(objectPoints.size());\n",
    "\n",
    "    for(size_t i = 0; i < objectPoints.size(); ++i )\n",
    "    {\n",
    "        if (fisheye)\n",
    "        {\n",
    "            fisheye::projectPoints(objectPoints[i], imagePoints2, rvecs[i], tvecs[i], cameraMatrix,\n",
    "                                   distCoeffs);\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            projectPoints(objectPoints[i], rvecs[i], tvecs[i], cameraMatrix, distCoeffs, imagePoints2);\n",
    "        }\n",
    "        err = norm(imagePoints[i], imagePoints2, NORM_L2);\n",
    "\n",
    "        size_t n = objectPoints[i].size();\n",
    "        perViewErrors[i] = (float) std::sqrt(err*err/n);\n",
    "        totalErr        += err*err;\n",
    "        totalPoints     += n;\n",
    "    }\n",
    "\n",
    "    return std::sqrt(totalErr/totalPoints);\n",
    "}\n",
    "//! [compute_errors]\n",
    "//! [board_corners]\n",
    "static void calcBoardCornerPositions(Size boardSize, float squareSize, vector<Point3f>& corners,\n",
    "                                     Settings::Pattern patternType /*= Settings::CHESSBOARD*/)\n",
    "{\n",
    "    corners.clear();\n",
    "\n",
    "    switch(patternType)\n",
    "    {\n",
    "    case Settings::CHESSBOARD:\n",
    "    case Settings::CIRCLES_GRID:\n",
    "        for( int i = 0; i < boardSize.height; ++i )\n",
    "            for( int j = 0; j < boardSize.width; ++j )\n",
    "                corners.push_back(Point3f(j*squareSize, i*squareSize, 0));\n",
    "        break;\n",
    "\n",
    "    case Settings::ASYMMETRIC_CIRCLES_GRID:\n",
    "        for( int i = 0; i < boardSize.height; i++ )\n",
    "            for( int j = 0; j < boardSize.width; j++ )\n",
    "                corners.push_back(Point3f((2*j + i % 2)*squareSize, i*squareSize, 0));\n",
    "        break;\n",
    "    default:\n",
    "        break;\n",
    "    }\n",
    "}\n",
    "//! [board_corners]\n",
    "static bool runCalibration( Settings& s, Size& imageSize, Mat& cameraMatrix, Mat& distCoeffs,\n",
    "                            vector<vector<Point2f> > imagePoints, vector<Mat>& rvecs, vector<Mat>& tvecs,\n",
    "                            vector<float>& reprojErrs,  double& totalAvgErr, vector<Point3f>& newObjPoints,\n",
    "                            float grid_width, bool release_object)\n",
    "{\n",
    "    //! [fixed_aspect]\n",
    "    cameraMatrix = Mat::eye(3, 3, CV_64F);\n",
    "    if( !s.useFisheye && s.flag & CALIB_FIX_ASPECT_RATIO )\n",
    "        cameraMatrix.at<double>(0,0) = s.aspectRatio;\n",
    "    //! [fixed_aspect]\n",
    "    if (s.useFisheye) {\n",
    "        distCoeffs = Mat::zeros(4, 1, CV_64F);\n",
    "    } else {\n",
    "        distCoeffs = Mat::zeros(8, 1, CV_64F);\n",
    "    }\n",
    "\n",
    "    vector<vector<Point3f> > objectPoints(1);\n",
    "    calcBoardCornerPositions(s.boardSize, s.squareSize, objectPoints[0], s.calibrationPattern);\n",
    "    objectPoints[0][s.boardSize.width - 1].x = objectPoints[0][0].x + grid_width;\n",
    "    newObjPoints = objectPoints[0];\n",
    "\n",
    "    objectPoints.resize(imagePoints.size(),objectPoints[0]);\n",
    "\n",
    "    //Find intrinsic and extrinsic camera parameters\n",
    "    double rms;\n",
    "\n",
    "    if (s.useFisheye) {\n",
    "        Mat _rvecs, _tvecs;\n",
    "        rms = fisheye::calibrate(objectPoints, imagePoints, imageSize, cameraMatrix, distCoeffs, _rvecs,\n",
    "                                 _tvecs, s.flag);\n",
    "\n",
    "        rvecs.reserve(_rvecs.rows);\n",
    "        tvecs.reserve(_tvecs.rows);\n",
    "        for(int i = 0; i < int(objectPoints.size()); i++){\n",
    "            rvecs.push_back(_rvecs.row(i));\n",
    "            tvecs.push_back(_tvecs.row(i));\n",
    "        }\n",
    "    } else {\n",
    "        int iFixedPoint = -1;\n",
    "        if (release_object)\n",
    "            iFixedPoint = s.boardSize.width - 1;\n",
    "        rms = calibrateCameraRO(objectPoints, imagePoints, imageSize, iFixedPoint,\n",
    "                                cameraMatrix, distCoeffs, rvecs, tvecs, newObjPoints,\n",
    "                                s.flag | CALIB_USE_LU);\n",
    "    }\n",
    "\n",
    "    if (release_object) {\n",
    "        cout << \"New board corners: \" << endl;\n",
    "        cout << newObjPoints[0] << endl;\n",
    "        cout << newObjPoints[s.boardSize.width - 1] << endl;\n",
    "        cout << newObjPoints[s.boardSize.width * (s.boardSize.height - 1)] << endl;\n",
    "        cout << newObjPoints.back() << endl;\n",
    "    }\n",
    "\n",
    "    cout << \"Re-projection error reported by calibrateCamera: \"<< rms << endl;\n",
    "\n",
    "    bool ok = checkRange(cameraMatrix) && checkRange(distCoeffs);\n",
    "\n",
    "    objectPoints.clear();\n",
    "    objectPoints.resize(imagePoints.size(), newObjPoints);\n",
    "    totalAvgErr = computeReprojectionErrors(objectPoints, imagePoints, rvecs, tvecs, cameraMatrix,\n",
    "                                            distCoeffs, reprojErrs, s.useFisheye);\n",
    "\n",
    "    return ok;\n",
    "}\n",
    "\n",
    "// Print camera parameters to the output file\n",
    "static void saveCameraParams( Settings& s, Size& imageSize, Mat& cameraMatrix, Mat& distCoeffs,\n",
    "                              const vector<Mat>& rvecs, const vector<Mat>& tvecs,\n",
    "                              const vector<float>& reprojErrs, const vector<vector<Point2f> >& imagePoints,\n",
    "                              double totalAvgErr, const vector<Point3f>& newObjPoints )\n",
    "{\n",
    "    FileStorage fs( s.outputFileName, FileStorage::WRITE );\n",
    "\n",
    "    time_t tm;\n",
    "    time( &tm );\n",
    "    struct tm *t2 = localtime( &tm );\n",
    "    char buf[1024];\n",
    "    strftime( buf, sizeof(buf), \"%c\", t2 );\n",
    "\n",
    "    fs << \"calibration_time\" << buf;\n",
    "\n",
    "    if( !rvecs.empty() || !reprojErrs.empty() )\n",
    "        fs << \"nr_of_frames\" << (int)std::max(rvecs.size(), reprojErrs.size());\n",
    "    fs << \"image_width\" << imageSize.width;\n",
    "    fs << \"image_height\" << imageSize.height;\n",
    "    fs << \"board_width\" << s.boardSize.width;\n",
    "    fs << \"board_height\" << s.boardSize.height;\n",
    "    fs << \"square_size\" << s.squareSize;\n",
    "\n",
    "    if( !s.useFisheye && s.flag & CALIB_FIX_ASPECT_RATIO )\n",
    "        fs << \"fix_aspect_ratio\" << s.aspectRatio;\n",
    "\n",
    "    if (s.flag)\n",
    "    {\n",
    "        std::stringstream flagsStringStream;\n",
    "        if (s.useFisheye)\n",
    "        {\n",
    "            flagsStringStream << \"flags:\"\n",
    "                << (s.flag & fisheye::CALIB_FIX_SKEW ? \" +fix_skew\" : \"\")\n",
    "                << (s.flag & fisheye::CALIB_FIX_K1 ? \" +fix_k1\" : \"\")\n",
    "                << (s.flag & fisheye::CALIB_FIX_K2 ? \" +fix_k2\" : \"\")\n",
    "                << (s.flag & fisheye::CALIB_FIX_K3 ? \" +fix_k3\" : \"\")\n",
    "                << (s.flag & fisheye::CALIB_FIX_K4 ? \" +fix_k4\" : \"\")\n",
    "                << (s.flag & fisheye::CALIB_RECOMPUTE_EXTRINSIC ? \" +recompute_extrinsic\" : \"\");\n",
    "        }\n",
    "        else\n",
    "        {\n",
    "            flagsStringStream << \"flags:\"\n",
    "                << (s.flag & CALIB_USE_INTRINSIC_GUESS ? \" +use_intrinsic_guess\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_ASPECT_RATIO ? \" +fix_aspectRatio\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_PRINCIPAL_POINT ? \" +fix_principal_point\" : \"\")\n",
    "                << (s.flag & CALIB_ZERO_TANGENT_DIST ? \" +zero_tangent_dist\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_K1 ? \" +fix_k1\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_K2 ? \" +fix_k2\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_K3 ? \" +fix_k3\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_K4 ? \" +fix_k4\" : \"\")\n",
    "                << (s.flag & CALIB_FIX_K5 ? \" +fix_k5\" : \"\");\n",
    "        }\n",
    "        fs.writeComment(flagsStringStream.str());\n",
    "    }\n",
    "\n",
    "    fs << \"flags\" << s.flag;\n",
    "\n",
    "    fs << \"fisheye_model\" << s.useFisheye;\n",
    "\n",
    "    fs << \"camera_matrix\" << cameraMatrix;\n",
    "    fs << \"distortion_coefficients\" << distCoeffs;\n",
    "\n",
    "    fs << \"avg_reprojection_error\" << totalAvgErr;\n",
    "    if (s.writeExtrinsics && !reprojErrs.empty())\n",
    "        fs << \"per_view_reprojection_errors\" << Mat(reprojErrs);\n",
    "\n",
    "    if(s.writeExtrinsics && !rvecs.empty() && !tvecs.empty() )\n",
    "    {\n",
    "        CV_Assert(rvecs[0].type() == tvecs[0].type());\n",
    "        Mat bigmat((int)rvecs.size(), 6, CV_MAKETYPE(rvecs[0].type(), 1));\n",
    "        bool needReshapeR = rvecs[0].depth() != 1 ? true : false;\n",
    "        bool needReshapeT = tvecs[0].depth() != 1 ? true : false;\n",
    "\n",
    "        for( size_t i = 0; i < rvecs.size(); i++ )\n",
    "        {\n",
    "            Mat r = bigmat(Range(int(i), int(i+1)), Range(0,3));\n",
    "            Mat t = bigmat(Range(int(i), int(i+1)), Range(3,6));\n",
    "\n",
    "            if(needReshapeR)\n",
    "                rvecs[i].reshape(1, 1).copyTo(r);\n",
    "            else\n",
    "            {\n",
    "                //*.t() is MatExpr (not Mat) so we can use assignment operator\n",
    "                CV_Assert(rvecs[i].rows == 3 && rvecs[i].cols == 1);\n",
    "                r = rvecs[i].t();\n",
    "            }\n",
    "\n",
    "            if(needReshapeT)\n",
    "                tvecs[i].reshape(1, 1).copyTo(t);\n",
    "            else\n",
    "            {\n",
    "                CV_Assert(tvecs[i].rows == 3 && tvecs[i].cols == 1);\n",
    "                t = tvecs[i].t();\n",
    "            }\n",
    "        }\n",
    "        fs.writeComment(\"a set of 6-tuples (rotation vector + translation vector) for each view\");\n",
    "        fs << \"extrinsic_parameters\" << bigmat;\n",
    "    }\n",
    "\n",
    "    if(s.writePoints && !imagePoints.empty() )\n",
    "    {\n",
    "        Mat imagePtMat((int)imagePoints.size(), (int)imagePoints[0].size(), CV_32FC2);\n",
    "        for( size_t i = 0; i < imagePoints.size(); i++ )\n",
    "        {\n",
    "            Mat r = imagePtMat.row(int(i)).reshape(2, imagePtMat.cols);\n",
    "            Mat imgpti(imagePoints[i]);\n",
    "            imgpti.copyTo(r);\n",
    "        }\n",
    "        fs << \"image_points\" << imagePtMat;\n",
    "    }\n",
    "\n",
    "    if( s.writeGrid && !newObjPoints.empty() )\n",
    "    {\n",
    "        fs << \"grid_points\" << newObjPoints;\n",
    "    }\n",
    "}\n",
    "\n",
    "//! [run_and_save]\n",
    "bool runCalibrationAndSave(Settings& s, Size imageSize, Mat& cameraMatrix, Mat& distCoeffs,\n",
    "                           vector<vector<Point2f> > imagePoints, float grid_width, bool release_object)\n",
    "{\n",
    "    vector<Mat> rvecs, tvecs;\n",
    "    vector<float> reprojErrs;\n",
    "    double totalAvgErr = 0;\n",
    "    vector<Point3f> newObjPoints;\n",
    "\n",
    "    bool ok = runCalibration(s, imageSize, cameraMatrix, distCoeffs, imagePoints, rvecs, tvecs, reprojErrs,\n",
    "                             totalAvgErr, newObjPoints, grid_width, release_object);\n",
    "    cout << (ok ? \"Calibration succeeded\" : \"Calibration failed\")\n",
    "         << \". avg re projection error = \" << totalAvgErr << endl;\n",
    "\n",
    "    if (ok)\n",
    "        saveCameraParams(s, imageSize, cameraMatrix, distCoeffs, rvecs, tvecs, reprojErrs, imagePoints,\n",
    "                         totalAvgErr, newObjPoints);\n",
    "    return ok;\n",
    "}\n",
    "//! [run_and_save]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab and independent exercises\n",
    "\n",
    "1. Write code to save and read the calibration file.\n",
    "2. Get a video of your own chessboard, calibrate your camera, and re-calculate the homography again. Then write code to rectify images in a video and show them side\n",
    "   by side.\n",
    "3. Using calibration images for the wide-angle Raspberry Pi camera on Matt's home robot, calibrate the camera then use the calibration to undistort the\n",
    "   videos provided from the camera thus far.\n",
    "4. Re-run your bird's-eye rectification from Lab 02 using the undistored images. Do you get a better result?\n",
    "\n",
    "## Report\n",
    "\n",
    "As always, turn in a report on your experiments and results by next lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCameraMatrix(h, w, mtx, dist, rvecs, tvecs, camera_settings_file):\n",
    "    fs = cv2.FileStorage(camera_settings_file, cv2.FILE_STORAGE_WRITE)\n",
    "    fs.write(\"image_height\", h)\n",
    "    fs.write(\"image_width\", w)\n",
    "    fs.write(\"Camera_matrix\", mtx)\n",
    "    fs.write(\"dist\", dist)\n",
    "    fs.write(\"rvecs\", np.array([rvecs]))\n",
    "    fs.write(\"tvecs\", np.array([tvecs]))\n",
    "    fs.release()\n",
    "\n",
    "def openCalibrationSettings(filename):\n",
    "\n",
    "    try:\n",
    "        fs = cv2.FileStorage(filename, cv2.FILE_STORAGE_READ)\n",
    "        h = fs.getNode(\"image_height\")\n",
    "        w = fs.getNode(\"image_width\")\n",
    "        mtx = fs.getNode(\"Camera_matrix\").mat()\n",
    "        dist = fs.getNode(\"dist\").mat()\n",
    "        rvecs = fs.getNode(\"rvecs\").mat().squeeze(0)\n",
    "        tvecs = fs.getNode(\"tvecs\").mat().squeeze(0)\n",
    "        print(\"Camera matrix : \\n\")\n",
    "        print(mtx)\n",
    "        print(\"dist : \\n\")\n",
    "        print(dist)\n",
    "        # print(\"rvecs : \\n\")\n",
    "        # print(rvecs)\n",
    "        # print(\"tvecs : \\n\")\n",
    "        # print(tvecs)\n",
    "        fs.release()\n",
    "        return h, w, mtx, dist, rvecs, tvecs\n",
    "    except:\n",
    "        print(\"Error occured in reading file.\")\n",
    "        raise ValueError()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Excercise # 3&4\n",
    "Accompanying video @ https://www.youtube.com/watch?v=H0BzzHHInrQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "def findObjectAndImagePoints(images):\n",
    "    # Defining the dimensions of checkerboard\n",
    "    \n",
    "    # CHECKERBOARD = (8,11)\n",
    "    CHECKERBOARD = (6,9)\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)\n",
    "\n",
    "    # Creating vector to store vectors of 3D points for each checkerboard image\n",
    "    objpoints = []\n",
    "    # Creating vector to store vectors of 2D points for each checkerboard image\n",
    "    imgpoints = [] \n",
    "\n",
    "\n",
    "    # Defining the world coordinates for 3D points\n",
    "    objp = np.zeros((1, CHECKERBOARD[0] * CHECKERBOARD[1], 3), np.float32)\n",
    "\n",
    "    objp[0,:,:2] = np.mgrid[0:CHECKERBOARD[0], 0:CHECKERBOARD[1]].T.reshape(-1, 2)\n",
    "\n",
    "    prev_img_shape = None\n",
    "    \n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "        # Find the chess board corners\n",
    "        # If desired number of corners are found in the image then ret = true\n",
    "        ret, corners = cv2.findChessboardCorners(gray, CHECKERBOARD, cv2.CALIB_CB_ADAPTIVE_THRESH + cv2.CALIB_CB_FAST_CHECK + cv2.CALIB_CB_NORMALIZE_IMAGE)\n",
    "        \n",
    "        \"\"\"\n",
    "        If desired number of corner are detected,\n",
    "        we refine the pixel coordinates and display \n",
    "        them on the images of checker board\n",
    "        \"\"\"\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            # refining pixel coordinates for given 2d points.\n",
    "            corners2 = cv2.cornerSubPix(gray, corners, (11,11),(-1,-1), criteria)\n",
    "            \n",
    "            imgpoints.append(corners2)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, CHECKERBOARD, corners2, ret)\n",
    "        \n",
    "        cv2.imshow('img', img)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "    return objpoints, imgpoints\n",
    "    \n",
    "    \n",
    "def calibrateAndSave(images, objpoints, imgpoints, camera_settings_file):\n",
    "    img = cv2.imread(images[0])\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    h,w = img.shape[:2]\n",
    "\n",
    "    \"\"\"\n",
    "    Performing camera calibration by \n",
    "    passing the value of known 3D points (objpoints)\n",
    "    and corresponding pixel coordinates of the \n",
    "    detected corners (imgpoints)\n",
    "    \"\"\"\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)\n",
    "\n",
    "    print(\"Camera matrix : \\n\")\n",
    "    print(mtx)\n",
    "    print(\"dist : \\n\")\n",
    "    print(dist)\n",
    "    print(\"rvecs : \\n\")\n",
    "    print(rvecs)\n",
    "    print(\"tvecs : \\n\")\n",
    "    print(tvecs)\n",
    "\n",
    "    saveCameraMatrix(h, w, mtx, dist, rvecs, tvecs, camera_settings_file)\n",
    "    findReprojectionError(objpoints, imgpoints, h, w, mtx, dist, rvecs, tvecs)\n",
    "    \n",
    "def saveCameraMatrix(h, w, mtx, dist, rvecs, tvecs, camera_settings_file):\n",
    "    fs = cv2.FileStorage(camera_settings_file, cv2.FILE_STORAGE_WRITE)\n",
    "    fs.write(\"image_height\", h)\n",
    "    fs.write(\"image_width\", w)\n",
    "    fs.write(\"Camera_matrix\", mtx)\n",
    "    fs.write(\"dist\", dist)\n",
    "    fs.write(\"rvecs\", np.array([rvecs]))\n",
    "    fs.write(\"tvecs\", np.array([tvecs]))\n",
    "    fs.release()\n",
    "\n",
    "def findReprojectionError(objpoints, imgpoints, h, w, mtx, dist, rvecs, tvecs):\n",
    "    ### FIND REPROJECTION ERROR\n",
    "    mean_error = 0\n",
    "    for i in range(len(objpoints)):\n",
    "        imgpoints2, _ = cv2.projectPoints(objpoints[i], rvecs[i], tvecs[i], mtx, dist)\n",
    "        error = cv2.norm(imgpoints[i], imgpoints2, cv2.NORM_L2)/len(imgpoints2)\n",
    "        mean_error += error\n",
    "    print( \"total error: {}\".format(mean_error/len(objpoints)) )\n",
    "    \n",
    "def showUndistorted(img, mtx, dist):\n",
    "    # Return undistorted images\n",
    "    \n",
    "    h,  w = img.shape[:2]\n",
    "    newcameramtx, roi = cv2.getOptimalNewCameraMatrix(mtx, dist, (w,h), 1, (w,h))\n",
    "    \n",
    "    mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, newcameramtx, (w,h), 5)\n",
    "    res = cv2.remap(img, mapx, mapy, cv2.INTER_LINEAR)\n",
    "    \n",
    "    # crop the image\n",
    "    x, y, w, h = roi\n",
    "    res = res[y:y+h, x:x+w]\n",
    "    return res\n",
    "        \n",
    "def openCalibrationSettings(filename):\n",
    "\n",
    "    try:\n",
    "        fs = cv2.FileStorage(filename, cv2.FILE_STORAGE_READ)\n",
    "        h = fs.getNode(\"image_height\")\n",
    "        w = fs.getNode(\"image_width\")\n",
    "        mtx = fs.getNode(\"Camera_matrix\").mat()\n",
    "        dist = fs.getNode(\"dist\").mat()\n",
    "        rvecs = fs.getNode(\"rvecs\").mat().squeeze(0)\n",
    "        tvecs = fs.getNode(\"tvecs\").mat().squeeze(0)\n",
    "        print(\"Camera matrix : \\n\")\n",
    "        print(mtx)\n",
    "        print(\"dist : \\n\")\n",
    "        print(dist)\n",
    "        # print(\"rvecs : \\n\")\n",
    "        # print(rvecs)\n",
    "        # print(\"tvecs : \\n\")\n",
    "        # print(tvecs)\n",
    "        fs.release()\n",
    "        return h, w, mtx, dist, rvecs, tvecs\n",
    "    except:\n",
    "        print(\"Error occured in reading file.\")\n",
    "        raise ValueError()\n",
    "\n",
    "def openHomographySettings(filename):\n",
    "    fs = cv2.FileStorage(filename, cv2.FILE_STORAGE_READ)\n",
    "    try:\n",
    "        h = fs.getNode(\"homography_matrix\").mat()\n",
    "        print(\"Homography matrix : \\n\")\n",
    "        print(h)\n",
    "        fs.release()\n",
    "        return h\n",
    "    except:\n",
    "        print(\"Error occured in reading file.\")\n",
    "        raise ValueError()\n",
    "    \n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    calibration_images_dir_name = \"sample-calib-images-jetson-rpicam\" \n",
    "    camera_settings_file = \"rpi_camera_parameters.yml\"\n",
    "    VIDEO_FILE = \"../robot.qt\"\n",
    "    homography_file = 'homography.yml'\n",
    "    homography_distorted_file = 'homography_distorted.yml'\n",
    "    \n",
    "    try:\n",
    "        h, w, mtx, dist, rvecs, tvecs = openCalibrationSettings(camera_settings_file)\n",
    "        print(\"Successfully loaded camera settings.\")\n",
    "    except:\n",
    "        # Extracting path of individual image stored in a given directory\n",
    "        images = glob.glob('../'+ calibration_images_dir_name +'/*.jpg')\n",
    "        print(\"Camera matrix file not found. Proceeding with calibration.\")\n",
    "        objpoints, imgpoints = findObjectAndImagePoints(images)\n",
    "        calibrateAndSave(images, objpoints, imgpoints, camera_settings_file)\n",
    "        print(\"Finished camera calibration.\")\n",
    "        h, w, mtx, dist, rvecs, tvecs = openCalibrationSettings(camera_settings_file)\n",
    "        \n",
    "    try:\n",
    "        homography_matrix = openHomographySettings(homography_file)\n",
    "        homography_matrix_distorted = openHomographySettings(homography_distorted_file)\n",
    "       \n",
    "    except:\n",
    "        sys.exit(\"Error opening Homography files\")\n",
    "        \n",
    "    \n",
    "    videoCapture = cv2.VideoCapture(VIDEO_FILE);\n",
    "    if not videoCapture.isOpened():\n",
    "        sys.exit(f\"ERROR! Unable to open input video file {VIDEO_FILE}\")\n",
    "        \n",
    "    width  = videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)   # float `width`\n",
    "    height = videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)  # float `height`\n",
    "    ratio = 640.0 / width\n",
    "    dim = (int(width * ratio), int(height * ratio))\n",
    "    \n",
    "    frame_size = (dim[0]*2, dim[1]*2)\n",
    "    # frame_size = (720, 480)\n",
    "    print(\"frame_size: \", frame_size)\n",
    "    OUTPUT_FILE = \"rectified_video.mp4\"\n",
    "    vidWriter = cv2.VideoWriter(OUTPUT_FILE, \n",
    "                         cv2.VideoWriter_fourcc('m','p','4','v'),\n",
    "                         15, frame_size)\n",
    "    \n",
    "    # Capture loop\n",
    "    key = -1\n",
    "    while (key != ord('q')):        # play video until press any key\n",
    "        # Get the next frame\n",
    "        _, img = videoCapture.read()\n",
    "        if img is None:   # no more frame capture from the video\n",
    "            # End of video file\n",
    "            break\n",
    "        \n",
    "        undistorted_img = showUndistorted(img, mtx, dist)\n",
    "        \n",
    "        h, w, ch = img.shape\n",
    "        rec = cv2.warpPerspective(img, homography_matrix_distorted, (w, h), cv2.INTER_LINEAR)\n",
    "        img = cv2.resize(img, dim)\n",
    "        img = cv2.putText(img = img, text = \"Original Image\", org = (10, 20),\n",
    "                          fontFace = cv2.FONT_HERSHEY_DUPLEX, fontScale = 0.5, color = (125, 246, 55), thickness = 2)\n",
    "        rec = cv2.resize(rec, dim)\n",
    "        res = cv2.putText(img = rec, text = \"Rectified Image / Projective Transform\", org = (10, 20),\n",
    "                          fontFace = cv2.FONT_HERSHEY_DUPLEX, fontScale = 0.5, color = (125, 246, 55), thickness = 2)\n",
    "        img = np.concatenate((img, rec), axis=1)\n",
    "        \n",
    "        h, w, ch = undistorted_img.shape\n",
    "        res = cv2.warpPerspective(undistorted_img, homography_matrix, (w, h), cv2.INTER_LINEAR)\n",
    "        undistorted_img = cv2.resize(undistorted_img, dim)\n",
    "        undistorted_img = cv2.putText(img = undistorted_img, text = \"undistorted_img\", org = (10, 20),\n",
    "                                fontFace = cv2.FONT_HERSHEY_DUPLEX, fontScale = 0.5, color = (125, 246, 55), thickness = 2)\n",
    "        \n",
    "        res = cv2.resize(res, dim)\n",
    "        res = cv2.putText(img = res, text = \"Projective Transform from Undistorted Image\", org = (10, 20),\n",
    "                                fontFace = cv2.FONT_HERSHEY_DUPLEX, fontScale = 0.5, color = (125, 246, 55), thickness = 2)\n",
    "        res = np.concatenate((undistorted_img, res), axis=1)\n",
    "        \n",
    "        res = np.concatenate((img, res), axis=0)\n",
    "        res = cv2.resize(res, frame_size)\n",
    "        # print(res.shape)\n",
    "        \n",
    "        #cv2.imshow('original_img', img)\n",
    "        vidWriter.write(res)\n",
    "        cv2.imshow('res', res)\n",
    "        key = cv2.waitKey(10)\n",
    "        \n",
    "    vidWriter.release()\n",
    "    videoCapture.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
